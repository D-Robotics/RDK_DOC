"use strict";(self.webpackChunkrdk_doc=self.webpackChunkrdk_doc||[]).push([[7769],{9286:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var r=n(74848),s=n(28453),o=n(93859),a=n(19365);const l={sidebar_position:5},i="5.4.5 Gesture Control The Car",c={id:"Robot_development/apps/car_gesture_control",title:"5.4.5 Gesture Control The Car",description:"Introduction",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/05_Robot_development/04_apps/car_gesture_control.md",sourceDirName:"05_Robot_development/04_apps",slug:"/Robot_development/apps/car_gesture_control",permalink:"/rdk_doc/en/Robot_development/apps/car_gesture_control",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/05_Robot_development/04_apps/car_gesture_control.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"5.4.4 Robot Follows the Human Body",permalink:"/rdk_doc/en/Robot_development/apps/car_tracking"},next:{title:"5.4.6 Voice Control The Car",permalink:"/rdk_doc/en/Robot_development/apps/car_audio_control"}},d={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Supported Platforms",id:"supported-platforms",level:2},{value:"Preparation",id:"preparation",level:2},{value:"RDK",id:"rdk",level:3},{value:"Instructions",id:"instructions",level:2},{value:"RDK",id:"rdk-1",level:3},{value:"Result Analysis",id:"result-analysis",level:2}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h1,{id:"545-gesture-control-the-car",children:"5.4.5 Gesture Control The Car"}),"\n","\n",(0,r.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(t.p,{children:"The app allows you to control a robot's movements using hand gestures, including left and right rotation and forward and backward translation. The app consists of MIPI image capture, human detection and tracking, hand keypoint detection, gesture recognition, gesture control strategy, image encoding and decoding, and web display. The workflow is shown in the following diagram:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:n(79965).A+"",width:"840",height:"682"})}),"\n",(0,r.jsx)(t.p,{children:"The supported control gestures, their corresponding functionalities, and examples of the gestures are as follows:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Control Gesture"}),(0,r.jsx)(t.th,{children:"Function"}),(0,r.jsx)(t.th,{children:"Gesture Action Example"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"666 Gesture/Awesome"}),(0,r.jsx)(t.td,{children:"Move forward"}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.img,{alt:"image-awesome",src:n(78990).A+"",width:"147",height:"144"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"yeah/Victory"}),(0,r.jsx)(t.td,{children:"Move backward"}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.img,{alt:"image-victory",src:n(55691).A+"",width:"147",height:"145"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Thumb Right"}),(0,r.jsx)(t.td,{children:"Turn right"}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.img,{alt:"image-thumbright",src:n(99553).A+"",width:"147",height:"145"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Thumb Left"}),(0,r.jsx)(t.td,{children:"Turn left"}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.img,{alt:"image-thumbleft",src:n(19732).A+"",width:"147",height:"145"})})]})]})]}),"\n",(0,r.jsx)(t.p,{children:"The app is demonstrated using a virtual car in the PC Gazebo simulation environment, but the control commands can also be directly used to control a physical robot."}),"\n",(0,r.jsxs)(t.p,{children:["Code repository:  (",(0,r.jsx)(t.a,{href:"https://github.com/D-Robotics/gesture_control",children:"https://github.com/D-Robotics/gesture_control"}),")"]}),"\n",(0,r.jsx)(t.h2,{id:"supported-platforms",children:"Supported Platforms"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Platform"}),(0,r.jsx)(t.th,{children:"System"}),(0,r.jsx)(t.th,{children:"Function"})]})}),(0,r.jsx)(t.tbody,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"RDK X3, RDK X3 Module, RDK X5"}),(0,r.jsx)(t.td,{children:"Ubuntu 20.04 (Foxy), Ubuntu 22.04 (Humble)"}),(0,r.jsx)(t.td,{children:"Start MIPI/USB camera to capture images, perform gesture recognition and control, and finally show the control effect through Gazebo"})]})})]}),"\n",(0,r.jsx)(t.h2,{id:"preparation",children:"Preparation"}),"\n",(0,r.jsx)(t.h3,{id:"rdk",children:"RDK"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"RDK is flashed the  Ubuntu 20.04/22.04 system image."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"TogetheROS.Bot successfully installed on RDK."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"MIPI or USB camera installed on RDK."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"PC on the same network segment as RDK (wired or connected to the same wireless network with the first three segments of the IP address matching). The PC needs to have the following software installed:"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(o.A,{groupId:"tros-distro",children:[(0,r.jsxs)(a.A,{value:"foxy",label:"Foxy",children:[(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["Ubuntu 20.04 system and ",(0,r.jsx)(t.a,{href:"https://docs.ros.org/en/foxy/Installation/Ubuntu-Install-Debians.html",children:"ROS2 Foxy Desktop Full"})]}),"\n",(0,r.jsx)(t.li,{children:"Gazebo and Turtlebot3 related packages. Installation commands:"}),"\n"]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"sudo apt-get install ros-foxy-gazebo-*\nsudo apt install ros-foxy-turtlebot3\nsudo apt install ros-foxy-turtlebot3-simulations\n"})})]}),(0,r.jsxs)(a.A,{value:"humble",label:"Humble",children:[(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["Ubuntu 22.04 system and ",(0,r.jsx)(t.a,{href:"https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html",children:"ROS2 Humble Desktop Full"})]}),"\n",(0,r.jsx)(t.li,{children:"Gazebo and Turtlebot3 related packages. Installation commands:"}),"\n"]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"sudo apt-get install ros-humble-gazebo-*\nsudo apt install ros-humble-turtlebot3\nsudo apt install ros-humble-turtlebot3-simulations\n"})})]})]}),"\n",(0,r.jsx)(t.h2,{id:"instructions",children:"Instructions"}),"\n",(0,r.jsx)(t.h3,{id:"rdk-1",children:"RDK"}),"\n",(0,r.jsx)(t.p,{children:'After running the car gesture control app, use the "666/Awesome" gesture to make the car move forward, use the "yeah/Victory" gesture to make the car move backward, use the "ThumbRight" gesture to make the car turn right, and use the "ThumbLeft" gesture to make the car turn left. The directions for turning left and right are based on the direction of the person\'s left and right (the direction of the thumb).'}),"\n",(0,r.jsxs)(t.p,{children:["Once the app is launched, you can view the images published by the sensor and the corresponding algorithm results on the PC browser (enter  ",(0,r.jsx)(t.code,{children:"http://IP:8000"})," in the browser, where IP is the IP address of the RDK)."]}),"\n",(0,r.jsx)(t.p,{children:"Launch the simulation environment on the PC:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"source /opt/ros/foxy/setup.bash\nexport TURTLEBOT3_MODEL=burger\nros2 launch turtlebot3_gazebo empty_world.launch.py\n"})}),"\n",(0,r.jsx)(t.p,{children:"After successful launch, the car in the simulation environment will look like this:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:n(6557).A+"",width:"960",height:"563"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Publishing Images from the MIPI Camera"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n\n# Copy the necessary configuration files for running the example from the installation path of tros.b.\ncp -r /opt/tros/lib/mono2d_body_detection/config/ .\ncp -r /opt/tros/lib/hand_lmk_detection/config/ .\ncp -r /opt/tros/lib/hand_gesture_detection/config/ .\n\n# Configure the MIPI camera\nexport CAM_TYPE=mipi\n\n# Launch the launch file\nros2 launch gesture_control gesture_control.launch.py\n"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Publishing Images from the USB Camera"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"# Configure the tros.b environment\nsource /opt/tros/setup.bash\n\n# Copy the necessary configuration files for running the example from the installation path of tros.b.\ncp -r /opt/tros/lib/mono2d_body_detection/config/ .\ncp -r /opt/tros/lib/hand_lmk_detection/config/ .\ncp -r /opt/tros/lib/hand_gesture_detection/config/ .\n\n# Configure USB camera\nexport CAM_TYPE=usb\n\n# Launch the launch file\nros2 launch gesture_control gesture_control.launch.py\n"})}),"\n",(0,r.jsx)(t.h2,{id:"result-analysis",children:"Result Analysis"}),"\n",(0,r.jsx)(t.p,{children:"The terminal output on the RDK shows the following information:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"[gesture_control-7] [WARN] [1652965757.159500951] [GestureControlEngine]: frame_ts_ms: 3698315358, track_id: 2, tracking_sta: 1, gesture: 14\n[gesture_control-7] [WARN] [1652965757.159660358] [GestureControlEngine]: do move, direction: 0, step: 0.500000\n[gesture_control-7] [WARN] [1652965757.211420964] [GestureControlEngine]: frame_ts_ms: 3698315425, track_id: 2, tracking_sta: 1, gesture: 14\n[gesture_control-7] [WARN] [1652965757.211624899] [GestureControlEngine]: do move, direction: 0, step: 0.500000\n[gesture_control-7] [WARN] [1652965757.232051230] [GestureControlEngine]: frame_ts_ms: 3698315457, track_id: 2, tracking_sta: 1, gesture: 14\n[gesture_control-7] [WARN] [1652965757.232207513] [GestureControlEngine]: do move, direction: 0, step: 0.500000\n"})}),"\n",(0,r.jsx)(t.p,{children:"The above log snippet shows the processing results of controlling the movement of the car through gestures. The value of tracking_sta is 1, indicating that gesture control is enabled, while a value of 0 indicates gesture recognition."}),"\n",(0,r.jsx)(t.p,{children:"Starting from the timestamp frame_ts_ms: 3698315358, the car is controlled to move forward at a speed of 0.5m/s using the 666 gesture (gesture: 14) (do move, direction: 0, step: 0.500000)."}),"\n",(0,r.jsxs)(t.p,{children:["On the PC, the command ",(0,r.jsx)(t.code,{children:"ros2 topic list"})," can be used in the terminal to query the topic information of the RDK:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"$ ros2 topic list\n/camera_info\n/cmd_vel\n/hbmem_img04054242060426080500012020112713\n/hobot_hand_gesture_detection\n/hobot_hand_lmk_detection\n/hobot_mono2d_body_detection\n/image\n/parameter_events\n/rosout\n"})}),"\n",(0,r.jsxs)(t.p,{children:["Among them, ",(0,r.jsx)(t.code,{children:"/image"})," is the image captured by the MIPI sensor and encoded in JPEG format, ",(0,r.jsx)(t.code,{children:"/hobot_hand_gesture_detection"})," is the algorithm message published by the RDK containing gesture recognition information, and ",(0,r.jsx)(t.code,{children:"/cmd_vel"})," is the motion control command published by the RDK."]}),"\n",(0,r.jsxs)(t.p,{children:["On the PC, the command ",(0,r.jsx)(t.code,{children:"ros2 topic echo /cmd_vel"})," can be used in the terminal to view the motion control command published by the RDK:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"linear:\n  x: -0.5\n  y: 0.0\n  z: 0.0\nangular:\n  x: 0.0\n  y: 0.0\n  z: 0.0\n---\nlinear:\n  x: 0.0\n  y: 0.0\n  z: 0.0\nangular:\n  x: 0.0\n  y: 0.0\n  z: -0.5\n---\n"})}),"\n",(0,r.jsx)(t.p,{children:"The car moves according to the gestures in the PC simulation environment, and the simulated car movement is as follows:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{src:n(1646).A+"",width:"960",height:"540"})})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},19365:(e,t,n)=>{n.d(t,{A:()=>a});n(96540);var r=n(34164);const s={tabItem:"tabItem_Ymn6"};var o=n(74848);function a(e){let{children:t,hidden:n,className:a}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,r.A)(s.tabItem,a),hidden:n,children:t})}},93859:(e,t,n)=>{n.d(t,{A:()=>y});var r=n(96540),s=n(34164),o=n(86641),a=n(56347),l=n(205),i=n(38874),c=n(24035),d=n(82993);function u(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??function(e){return u(e).map((e=>{let{props:{value:t,label:n,attributes:r,default:s}}=e;return{value:t,label:n,attributes:r,default:s}}))}(n);return function(e){const t=(0,c.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function p(e){let{queryString:t=!1,groupId:n}=e;const s=(0,a.W6)(),o=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,i.aZ)(o),(0,r.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(s.location.search);t.set(o,e),s.replace({...s.location,search:t.toString()})}),[o,s])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:s}=e,o=h(e),[a,i]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:t,tabValues:o}))),[c,u]=p({queryString:n,groupId:s}),[g,b]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[s,o]=(0,d.Dv)(n);return[s,(0,r.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:s}),f=(()=>{const e=c??g;return m({value:e,tabValues:o})?e:null})();(0,l.A)((()=>{f&&i(f)}),[f]);return{selectedValue:a,selectValue:(0,r.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),b(e)}),[u,b,o]),tabValues:o}}var b=n(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function j(e){let{className:t,block:n,selectedValue:r,selectValue:a,tabValues:l}=e;const i=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.a_)(),d=e=>{const t=e.currentTarget,n=i.indexOf(t),s=l[n].value;s!==r&&(c(t),a(s))},u=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;t=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;t=i[n]??i[i.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},t),children:l.map((e=>{let{value:t,label:n,attributes:o}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:r===t?0:-1,"aria-selected":r===t,ref:e=>i.push(e),onKeyDown:u,onClick:d,...o,className:(0,s.A)("tabs__item",f.tabItem,o?.className,{"tabs__item--active":r===t}),children:n??t},t)}))})}function _(e){let{lazy:t,children:n,selectedValue:s}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===s));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:o.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function v(e){const t=g(e);return(0,x.jsxs)("div",{className:(0,s.A)("tabs-container",f.tabList),children:[(0,x.jsx)(j,{...t,...e}),(0,x.jsx)(_,{...t,...e})]})}function y(e){const t=(0,b.A)();return(0,x.jsx)(v,{...e,children:u(e.children)},String(t))}},6557:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/gazebo-0e43917a538ed038fba57f6d0e669957.jpeg"},1646:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/gesture_ctrl-6af00aa02aba5b6f934e02e99f6f47b6.gif"},79965:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/gesture_ctrl_workflow-320b1678f6c69ba4e411a09a4992245d.jpg"},78990:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/image-awesome-a47b44f9f6d0425d7e88ec2f05b64d16.jpeg"},19732:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/image-thumbleft-dc4842190d5dcf6b2f96907125df97dd.jpeg"},99553:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/image-thumbright-ec85f3a3a20cd2b2944e284e318adb11.jpeg"},55691:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/image-victory-13c483b7b905156f2c5ced2abf0edaee.jpeg"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>l});var r=n(96540);const s={},o=r.createContext(s);function a(e){const t=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);